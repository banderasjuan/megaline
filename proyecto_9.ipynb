{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Tienes acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del sprint de Análisis estadístico de datos). Para esta tarea de clasificación debes crear un modelo que escoja el plan correcto. Como ya hiciste el paso de procesar los datos, puedes lanzarte directo a crear el modelo.\n",
    "\n",
    "Desarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usa el dataset para comprobar la exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importemos la librerias que vamos a necesitar \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carguemos datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carguemos los datos \n",
    "megaline = pd.read_csv('./users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megaline.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "megaline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megaline.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos están en el formato correcto "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que los datos están listos, vamos a hacer la segmentación del dt en 3 (Entrenamiento, Validación y Prueba) para poder crear nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dividimos nuestro DT en 2 (Entrenamiento y Validación&Prueba)\n",
    "mega_train , mega_valid_test = train_test_split(megaline, random_state= 345, test_size=0.3)\n",
    "#Dividamos nuestro nuevo set mega_valid_test en 2 (Validación y Prueba)\n",
    "mega_valid , mega_test = train_test_split(mega_valid_test, random_state=345, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos nuestros 3 datasets: \n",
    "- mega_train para entrenar al modelo (70%)\n",
    "- mega_valid para validar nuestro modelo (15%)\n",
    "- mega_test para probar nuestro modelo. (15%)\n",
    "\n",
    "Decidí entrenar el modelo con el 70% de la información porque creo que mientras mas información tenga para entrenar será más exacto. Pero ya lo veremos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separemos los features del target de cada dt \n",
    "train_features = mega_train.drop(columns='is_ultra')\n",
    "train_target = mega_train['is_ultra']\n",
    "valid_features = mega_valid.drop(columns='is_ultra')\n",
    "valid_target = mega_valid['is_ultra']\n",
    "test_features = mega_test.drop(columns='is_ultra')\n",
    "test_target = mega_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos nuestros datos listos para crear nuestros modelos. Nuestro target es la columna 'is_ultra' y nuestro modelo tendrá que predecir si los usuarios serán Smart(0) o Ultra(1). por lo que utilizaremos modelos de clasificación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación y validación de Modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth= 1 :0.7261410788381742\n",
      "max_depth= 2 :0.7427385892116183\n",
      "max_depth= 3 :0.7634854771784232\n",
      "max_depth= 4 :0.7676348547717843\n",
      "max_depth= 5 :0.7655601659751037\n"
     ]
    }
   ],
   "source": [
    "#vamos a crear un modelo y probemos varias profundidades para encontrar la correcta mediante un bucle \n",
    "for i in range(1,6):\n",
    "    tree_model = DecisionTreeClassifier(random_state=345, max_depth=i)\n",
    "    tree_model.fit(train_features,train_target)\n",
    "    tree_predictions =  tree_model.predict(valid_features)\n",
    "    print('max_depth=',i, \":\",end='')\n",
    "    print(accuracy_score(valid_target,tree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que de los modelos de árbol, el modelo con una max depth de 4, es el que tiene mayor exactitud en 0.7676348547717843"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validación (n_estimators = 12): 0.7925311203319502\n"
     ]
    }
   ],
   "source": [
    "# Vamos a crear un bucle que pruebe diferentes números de estimadores para determinar cual es el mejor\n",
    "bst_score = 0\n",
    "bst_est = 0 \n",
    "for est in range(1, 101):\n",
    "    r_model = RandomForestClassifier(random_state=345, n_estimators=est)\n",
    "    r_model.fit(train_features,train_target)\n",
    "    score_r = r_model.score(valid_features,valid_target)\n",
    "    if score_r > bst_score:\n",
    "        bst_score = score_r\n",
    "        bst_est = est\n",
    "print(\"La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(bst_est, bst_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que en el modelo de Random Forrest la mejor predicción la realiza con 12 bosque obteniendo 0.7925311203319502 de exactitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo en entranamiento: 0.7572254335260116\n",
      "Exactitud del modelo en validación 0.7116182572614108\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(random_state=345, solver='liblinear')\n",
    "log_model.fit(train_features,train_target)\n",
    "\n",
    "train_score  = log_model.score(train_features,train_target)\n",
    "log_score = log_model.score(valid_features,valid_target)\n",
    "\n",
    "print('Exactitud del modelo en entranamiento:',train_score)\n",
    "print('Exactitud del modelo en validación', log_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 3 modelos que hemos probado, el modelo de Random Forrest classifier es el que muestra una mayor exactitud al validar con el dataset de validación  CON 0.7925311203319502 DE EXACTITUD y es el modelo hemos decidido probar con el dataset de prueba. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calidad del Modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probemos el modelo ganador con el dataset de prueba. \n",
    "\n",
    "El modelo ganador fue el bosque de decisión con n_estimators = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de validación: 0.7925311203319502\n",
      "Model score: 0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "#Recapitulemos con el modelo y el dataset de validación y veamos su exactitud\n",
    "val_model = RandomForestClassifier(random_state=345, n_estimators=12)\n",
    "val_model.fit(train_features,train_target)\n",
    "val_score = val_model.score(valid_features,valid_target)\n",
    "print('Score de validación:', val_score)\n",
    "\n",
    "#probemos el modelo con el dataset de prueba y validemos su exactitud\n",
    "best_model = RandomForestClassifier(random_state=345, n_estimators = 12)\n",
    "best_model.fit(train_features,train_target)\n",
    "best_score = best_model.score(test_features,test_target)\n",
    "\n",
    "print('Model score:', best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de probar el modelo, observamos que tiene una exactitud de 0.782608695652174 . Lo cual comparado con el umbral de exactitud que tenemos para este proyecto de 0.75 es muy bueno. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos 3 modelos de clasificación distintos y corrimos pruebas para determinar los mejores parámetros. \n",
    "Podemos concluir que de los 3 modelos , el Random Forrest Classifier con un n_estimator de 12 es el que mejor exactitud tiene y por eso hemos decidido usarlo para probarlo con nuestro set de prueba. \n",
    "El umbral de exactitud que arrojó nuestra prueba de calidad es de 0.78 ,contra 0.75 que nos pide el proyecto. lo cual supera las expectativas. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
